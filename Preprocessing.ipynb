{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325970e9-cb2e-4fb4-9ece-10af0733e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6acaea-c07e-4be2-8108-2ca3d132534b",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31b8fdcf-28d3-4f0b-a060-a3ab180bbde8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC</th>\n",
       "      <th>TGT</th>\n",
       "      <th>VOT</th>\n",
       "      <th>RES</th>\n",
       "      <th>YEA</th>\n",
       "      <th>DAT</th>\n",
       "      <th>TXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steel1943</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>23:13, 19 April 2013</td>\n",
       "      <td>'''Support''' as co-nom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cuchullain</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>01:04, 20 April 2013</td>\n",
       "      <td>'''Support''' as nominator.--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INeverCry</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>23:43, 19 April 2013</td>\n",
       "      <td>'''Support''' per noms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cncmaster</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>00:11, 20 April 2013</td>\n",
       "      <td>'''Support''' per noms. BDD is a strong contri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Miniapolis</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>00:56, 20 April 2013</td>\n",
       "      <td>'''Support''', with great pleasure. I work wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198270</th>\n",
       "      <td>172</td>\n",
       "      <td>Vancouverguy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>02:51, 2 Sep 2003</td>\n",
       "      <td>Support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198271</th>\n",
       "      <td>Angela</td>\n",
       "      <td>WhisperToMe</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>23:45, 26 Nov 2003</td>\n",
       "      <td>Support.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198272</th>\n",
       "      <td>Jiang</td>\n",
       "      <td>WhisperToMe</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td></td>\n",
       "      <td>Support. --</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198273</th>\n",
       "      <td>Pakaran</td>\n",
       "      <td>WhisperToMe</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>05:38, 5 Dec 2003</td>\n",
       "      <td>Support.  Age has nothing to do with maturity....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198274</th>\n",
       "      <td>Jimregan</td>\n",
       "      <td>Zanimum</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td></td>\n",
       "      <td>Support - anyone who can write so much, and so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198275 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               SRC           TGT VOT RES   YEA                   DAT  \\\n",
       "0        Steel1943           BDD   1   1  2013  23:13, 19 April 2013   \n",
       "1       Cuchullain           BDD   1   1  2013  01:04, 20 April 2013   \n",
       "2        INeverCry           BDD   1   1  2013  23:43, 19 April 2013   \n",
       "3        Cncmaster           BDD   1   1  2013  00:11, 20 April 2013   \n",
       "4       Miniapolis           BDD   1   1  2013  00:56, 20 April 2013   \n",
       "...            ...           ...  ..  ..   ...                   ...   \n",
       "198270         172  Vancouverguy   1   1  2003     02:51, 2 Sep 2003   \n",
       "198271      Angela   WhisperToMe   1   1  2003    23:45, 26 Nov 2003   \n",
       "198272       Jiang   WhisperToMe   1   1  2003                         \n",
       "198273     Pakaran   WhisperToMe   1   1  2003     05:38, 5 Dec 2003   \n",
       "198274    Jimregan       Zanimum   1   1  2003                         \n",
       "\n",
       "                                                      TXT  \n",
       "0                                '''Support''' as co-nom.  \n",
       "1                           '''Support''' as nominator.--  \n",
       "2                                 '''Support''' per noms.  \n",
       "3       '''Support''' per noms. BDD is a strong contri...  \n",
       "4       '''Support''', with great pleasure. I work wit...  \n",
       "...                                                   ...  \n",
       "198270                                            Support  \n",
       "198271                                           Support.  \n",
       "198272                                        Support. --  \n",
       "198273  Support.  Age has nothing to do with maturity....  \n",
       "198274  Support - anyone who can write so much, and so...  \n",
       "\n",
       "[198275 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'Data/ground/wiki-RfA.txt'\n",
    "\n",
    "output_file = 'Data/wiki_RfA_2010_2013.csv'\n",
    "\n",
    "\n",
    "def process_file_to_dataframe(file_path):\n",
    "    # Read the text file as lines\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Split the content by empty lines\n",
    "    entries = content.strip().split('\\n\\n')\n",
    "\n",
    "    # List to store the entries in a structured format\n",
    "    data = []\n",
    "\n",
    "    # Process each entry\n",
    "    for entry in entries:\n",
    "        entry_dict = {}\n",
    "        for line in entry.split('\\n'):\n",
    "            if \":\" in line:\n",
    "                key, value = line.split(\":\", 1)\n",
    "                entry_dict[key.strip()] = value.strip()\n",
    "        data.append(entry_dict)\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Process and filter the data by year (2010 to 2013)\n",
    "def filter_data_by_year(df):\n",
    "    # Convert 'YEA' column to numeric, errors='coerce' will convert non-numeric to NaN\n",
    "    df['YEA'] = pd.to_numeric(df['YEA'], errors='coerce')\n",
    "\n",
    "    # Filter the DataFrame for years between 2010 and 2013\n",
    "    filtered_df = df[(df['YEA'] >= 2010) & (df['YEA'] <= 2013)]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Write the filtered data to a CSV file\n",
    "def write_csv_file(df, output_file):\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2eed568-e073-4d08-adfc-3dae175dc8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file with data from 2010 to 2013 has been written to: Data/wiki_RfA_2010_2013.csv\n"
     ]
    }
   ],
   "source": [
    "# Main processing pipeline\n",
    "df = process_file_to_dataframe(file_path)  # Process the file into a DataFrame\n",
    "filtered_df = filter_data_by_year(df)      # Filter data for 2010-2013\n",
    "write_csv_file(filtered_df, output_file)   # Write the filtered data to CSV\n",
    "\n",
    "print(f\"CSV file with data from 2010 to 2013 has been written to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8564e88f-45ad-4242-9a15-38e18a914f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: Index(['SRC', 'TGT', 'VOT', 'RES', 'YEA', 'DAT', 'TXT'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rfaSet = 'Data/wiki_RfA_2010_2013.csv'\n",
    "\n",
    "\n",
    "df = pd.read_csv(rfaSet)\n",
    "print(\"Columns in DataFrame:\", df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65146c0a-04b4-43e3-9750-3b0942128d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC</th>\n",
       "      <th>TGT</th>\n",
       "      <th>VOT</th>\n",
       "      <th>RES</th>\n",
       "      <th>YEA</th>\n",
       "      <th>DAT</th>\n",
       "      <th>TXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steel1943</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-19 23:13:00</td>\n",
       "      <td>'''Support''' as co-nom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cuchullain</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-20 01:04:00</td>\n",
       "      <td>'''Support''' as nominator.--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INeverCry</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-19 23:43:00</td>\n",
       "      <td>'''Support''' per noms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cncmaster</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-20 00:11:00</td>\n",
       "      <td>'''Support''' per noms. BDD is a strong contri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Miniapolis</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-20 00:56:00</td>\n",
       "      <td>'''Support''', with great pleasure. I work wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32305</th>\n",
       "      <td>Atama</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:17:00</td>\n",
       "      <td>'''Oppose''' - Per Polargeo, and per [http://e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32306</th>\n",
       "      <td>Bradjamesbrown</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:18:00</td>\n",
       "      <td>'''Oppose''' per SilkTork's diff above. Assert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32307</th>\n",
       "      <td>Ottawa4ever</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:11:00</td>\n",
       "      <td>'''Neutral''' Not to pile on, neutral. I canno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32308</th>\n",
       "      <td>Tryptofish</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 17:58:00</td>\n",
       "      <td>'''Neutral''' I've interacted with this editor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32309</th>\n",
       "      <td>The High Fin Sperm Whale</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:34:00</td>\n",
       "      <td>'''Neutral''' Although we do need more admins ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32310 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            SRC     TGT  VOT  RES   YEA                  DAT  \\\n",
       "0                     Steel1943     BDD    1    1  2013  2013-04-19 23:13:00   \n",
       "1                    Cuchullain     BDD    1    1  2013  2013-04-20 01:04:00   \n",
       "2                     INeverCry     BDD    1    1  2013  2013-04-19 23:43:00   \n",
       "3                     Cncmaster     BDD    1    1  2013  2013-04-20 00:11:00   \n",
       "4                    Miniapolis     BDD    1    1  2013  2013-04-20 00:56:00   \n",
       "...                         ...     ...  ...  ...   ...                  ...   \n",
       "32305                     Atama  ZooPro   -1   -1  2010  2010-02-22 18:17:00   \n",
       "32306            Bradjamesbrown  ZooPro   -1   -1  2010  2010-02-22 18:18:00   \n",
       "32307               Ottawa4ever  ZooPro    0   -1  2010  2010-02-22 18:11:00   \n",
       "32308                Tryptofish  ZooPro    0   -1  2010  2010-02-22 17:58:00   \n",
       "32309  The High Fin Sperm Whale  ZooPro    0   -1  2010  2010-02-22 18:34:00   \n",
       "\n",
       "                                                     TXT  \n",
       "0                               '''Support''' as co-nom.  \n",
       "1                          '''Support''' as nominator.--  \n",
       "2                                '''Support''' per noms.  \n",
       "3      '''Support''' per noms. BDD is a strong contri...  \n",
       "4      '''Support''', with great pleasure. I work wit...  \n",
       "...                                                  ...  \n",
       "32305  '''Oppose''' - Per Polargeo, and per [http://e...  \n",
       "32306  '''Oppose''' per SilkTork's diff above. Assert...  \n",
       "32307  '''Neutral''' Not to pile on, neutral. I canno...  \n",
       "32308  '''Neutral''' I've interacted with this editor...  \n",
       "32309  '''Neutral''' Although we do need more admins ...  \n",
       "\n",
       "[32310 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ddd669-66ec-401f-96d2-27e356004fe9",
   "metadata": {},
   "source": [
    "#### Treating time DAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9af3a72-d0a5-4f78-869f-6b1412beeadd",
   "metadata": {},
   "source": [
    "removing edges with not time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcb9f2c6-da8d-4477-9b45-17db45980d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SRC                TGT  VOT  RES   YEA DAT  \\\n",
      "707            NaN        Jason Quinn    0    1  2013 NaT   \n",
      "708            NaN        Jason Quinn    0    1  2013 NaT   \n",
      "793            NaN            Legoktm    1    1  2013 NaT   \n",
      "969    Majoreditor          Lord Roem    1    1  2013 NaT   \n",
      "1126           NaN      Mattythewhite   -1    1  2013 NaT   \n",
      "...            ...                ...  ...  ...   ...  ..   \n",
      "32310      Davidwr           Venomcuz   -1   -1  2010 NaT   \n",
      "32346       Begoon      White Shadows   -1   -1  2010 NaT   \n",
      "32350          NaN      White Shadows   -1   -1  2010 NaT   \n",
      "32394          NaN         WikiCopter   -1   -1  2010 NaT   \n",
      "32522          NaN  William S. Saturn   -1   -1  2010 NaT   \n",
      "\n",
      "                                                     TXT  \n",
      "707                                                  NaN  \n",
      "708                                                  NaN  \n",
      "793                                                  NaN  \n",
      "969    '''Support'''. The candidate is a good content...  \n",
      "1126                                                 NaN  \n",
      "...                                                  ...  \n",
      "32310                                       '''Oppose'''  \n",
      "32346  '''Oppose''' Sorry. I can't support with the m...  \n",
      "32350                                                NaN  \n",
      "32394                                                NaN  \n",
      "32522                                                NaN  \n",
      "\n",
      "[262 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'DAT' column to datetime, invalid parsing will result in NaT\n",
    "df['DAT'] = pd.to_datetime(df['DAT'], format='%H:%M, %d %B %Y', errors='coerce')\n",
    "\n",
    "# Filter rows where 'DAT' is NaT\n",
    "nat_rows = df[df['DAT'].isna()]\n",
    "\n",
    "# Display the rows with NaT in the 'DAT' column\n",
    "print(nat_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99daf37f-0175-4788-9dce-42fe88d5abdf",
   "metadata": {},
   "source": [
    "out of 32522 we found 262 edges with invalid/ NaN time - removing them for a better analysis and inegration of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127833c4-fe57-46a9-b1f0-0f31d828db26",
   "metadata": {},
   "source": [
    "#### removing those DAT timeless edges - RUN ONLY ONCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc61e184-baed-411d-935b-3a8f38069206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with NA in DAT: 262\n",
      "Number of rows with NA in DAT: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(rfaSet)\n",
    "\n",
    "# Convert 'DAT' to datetime, coercing errors to NaT (invalid datetimes)\n",
    "df['DAT'] = pd.to_datetime(df['DAT'], format='%H:%M, %d %B %Y', errors='coerce')\n",
    "\n",
    "na_count = df['DAT'].isna().sum()\n",
    "print(f\"Number of rows with NA in DAT: {na_count}\")\n",
    "\n",
    "# Remove rows where DAT is NaT (missing or invalid datetime)\n",
    "df_cleaned = df.dropna(subset=['DAT'])\n",
    "\n",
    "\n",
    "na_count = df_cleaned['DAT'].isna().sum()\n",
    "print(f\"Number of rows with NA in DAT: {na_count}\")\n",
    "\n",
    "# Print the cleaned dataframe\n",
    "write_csv_file(df_cleaned, output_file)  \n",
    "\n",
    "#preprocessing DONE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d52d53-c927-4ee0-8c4f-5b6c90daacc5",
   "metadata": {},
   "source": [
    "##### PRE PROCESSING DONE - JUST USE THE CLEANED CVS FILE FROM NOW ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee545945-d068-427e-8b66-459b54fc5838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC</th>\n",
       "      <th>TGT</th>\n",
       "      <th>VOT</th>\n",
       "      <th>RES</th>\n",
       "      <th>YEA</th>\n",
       "      <th>DAT</th>\n",
       "      <th>TXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steel1943</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-19 23:13:00</td>\n",
       "      <td>'''Support''' as co-nom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cuchullain</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-20 01:04:00</td>\n",
       "      <td>'''Support''' as nominator.--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INeverCry</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-19 23:43:00</td>\n",
       "      <td>'''Support''' per noms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cncmaster</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-20 00:11:00</td>\n",
       "      <td>'''Support''' per noms. BDD is a strong contri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Miniapolis</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-20 00:56:00</td>\n",
       "      <td>'''Support''', with great pleasure. I work wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32305</th>\n",
       "      <td>Atama</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:17:00</td>\n",
       "      <td>'''Oppose''' - Per Polargeo, and per [http://e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32306</th>\n",
       "      <td>Bradjamesbrown</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:18:00</td>\n",
       "      <td>'''Oppose''' per SilkTork's diff above. Assert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32307</th>\n",
       "      <td>Ottawa4ever</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:11:00</td>\n",
       "      <td>'''Neutral''' Not to pile on, neutral. I canno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32308</th>\n",
       "      <td>Tryptofish</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 17:58:00</td>\n",
       "      <td>'''Neutral''' I've interacted with this editor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32309</th>\n",
       "      <td>The High Fin Sperm Whale</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:34:00</td>\n",
       "      <td>'''Neutral''' Although we do need more admins ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32310 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            SRC     TGT  VOT  RES   YEA                  DAT  \\\n",
       "0                     Steel1943     BDD    1    1  2013  2013-04-19 23:13:00   \n",
       "1                    Cuchullain     BDD    1    1  2013  2013-04-20 01:04:00   \n",
       "2                     INeverCry     BDD    1    1  2013  2013-04-19 23:43:00   \n",
       "3                     Cncmaster     BDD    1    1  2013  2013-04-20 00:11:00   \n",
       "4                    Miniapolis     BDD    1    1  2013  2013-04-20 00:56:00   \n",
       "...                         ...     ...  ...  ...   ...                  ...   \n",
       "32305                     Atama  ZooPro   -1   -1  2010  2010-02-22 18:17:00   \n",
       "32306            Bradjamesbrown  ZooPro   -1   -1  2010  2010-02-22 18:18:00   \n",
       "32307               Ottawa4ever  ZooPro    0   -1  2010  2010-02-22 18:11:00   \n",
       "32308                Tryptofish  ZooPro    0   -1  2010  2010-02-22 17:58:00   \n",
       "32309  The High Fin Sperm Whale  ZooPro    0   -1  2010  2010-02-22 18:34:00   \n",
       "\n",
       "                                                     TXT  \n",
       "0                               '''Support''' as co-nom.  \n",
       "1                          '''Support''' as nominator.--  \n",
       "2                                '''Support''' per noms.  \n",
       "3      '''Support''' per noms. BDD is a strong contri...  \n",
       "4      '''Support''', with great pleasure. I work wit...  \n",
       "...                                                  ...  \n",
       "32305  '''Oppose''' - Per Polargeo, and per [http://e...  \n",
       "32306  '''Oppose''' per SilkTork's diff above. Assert...  \n",
       "32307  '''Neutral''' Not to pile on, neutral. I canno...  \n",
       "32308  '''Neutral''' I've interacted with this editor...  \n",
       "32309  '''Neutral''' Although we do need more admins ...  \n",
       "\n",
       "[32310 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Data/wiki_RfA_2010_2013.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7f039f1-787b-417a-94a0-d2ea27f578e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming df is the DataFrame that you've already filtered and processed\n",
    "# Create a signed graph\n",
    "def create_signed_graph(df):\n",
    "    \"\"\"\n",
    "    Create a MultiDiGraph from a DataFrame with edges labeled by interaction type.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing columns for edges and attributes.\n",
    "\n",
    "    Returns:\n",
    "        G (nx.MultiDiGraph): The created graph.\n",
    "    \"\"\"\n",
    "    G = nx.MultiDiGraph()  # Use MultiDiGraph to allow multiple edges between nodes\n",
    "\n",
    "    # Iterate through the rows of the DataFrame to add edges and nodes\n",
    "    for _, row in df.iterrows():\n",
    "        src = row['SRC']  # Source node\n",
    "        tgt = row['TGT']  # Target node\n",
    "        vot = row['VOT']  # Label: -1, 1, or 0\n",
    "        txt = row['TXT']  # Additional textual information\n",
    "        res = row['RES']  # Admin status: 1 for admin, 0 for nonAdmin\n",
    "        dat = row['DAT']  # Date or timestamp attribute\n",
    "\n",
    "        # Add nodes if they don't already exist\n",
    "        if src not in G:\n",
    "            G.add_node(src)\n",
    "        if tgt not in G:\n",
    "            G.add_node(tgt)\n",
    "\n",
    "        # Determine admin status for the edge\n",
    "        admin_status = \"admin\" if res == 1 else \"nonAdmin\"\n",
    "\n",
    "        # Add edge with attributes, storing `VOT` as a label, not a weight\n",
    "        edge_attrs = {\n",
    "            'label': vot,   # Interaction type (-1, 0, 1)\n",
    "            'txt': txt,     # Additional text data\n",
    "            'admin': admin_status,  # Whether the interaction involves an admin\n",
    "            'DAT': dat      # Timestamp or date\n",
    "        }\n",
    "        G.add_edge(src, tgt, **edge_attrs)  # Add the edge with all attributes\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Create the signed graph\n",
    "G = create_signed_graph(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05995ca1-7885-4b0c-84be-b3c8227dc3e0",
   "metadata": {},
   "source": [
    "### Graph Characteristics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d538de5c-556c-4185-8b81-5ae72c1f084a",
   "metadata": {},
   "source": [
    "##### Number of Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c897a5e3-0ee5-48c5-b966-b33888c5f391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2968"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38785c-4d07-47b3-a842-d7c77ae1ed82",
   "metadata": {},
   "source": [
    "##### Number of Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16c3fcc1-e527-4920-ac61-46e2387b5c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32310"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb00ce-ddb7-4113-b426-1d08e3eb2c6d",
   "metadata": {},
   "source": [
    "#### Max Degree - TOP 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f728248-df61-4273-a8f9-ac0c45ac5864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 nodes by in-degree:\n",
      "User: HJ Mitchell, In-degree: 341\n",
      "User: Connormah, In-degree: 326\n",
      "User: Ironholds, In-degree: 294\n",
      "User: Lord Roem, In-degree: 272\n",
      "User: The Thing That Should Not Be, In-degree: 265\n",
      "User: Everyking, In-degree: 239\n",
      "User: SarekOfVulcan, In-degree: 237\n",
      "User: DeltaQuad, In-degree: 227\n",
      "User: GiantSnowman, In-degree: 220\n",
      "User: SarahStierch, In-degree: 218\n",
      "User: Σ, In-degree: 217\n",
      "User: Drmies, In-degree: 208\n",
      "User: Richwales, In-degree: 205\n",
      "User: My76Strat, In-degree: 201\n",
      "User: MZMcBride, In-degree: 199\n",
      "User: Slon02, In-degree: 196\n",
      "User: Theopolisme, In-degree: 189\n",
      "User: Dabomb87, In-degree: 189\n",
      "User: 28bytes, In-degree: 188\n",
      "User: Secret, In-degree: 187\n",
      "\n",
      "Top 20 nodes by out-degree:\n",
      "User: Boing! said Zebedee, Out-degree: 274\n",
      "User: Fetchcomms, Out-degree: 253\n",
      "User: Fastily, Out-degree: 251\n",
      "User: Ktr101, Out-degree: 249\n",
      "User: Axl, Out-degree: 211\n",
      "User: RP459, Out-degree: 198\n",
      "User: Kudpung, Out-degree: 197\n",
      "User: Minimac, Out-degree: 195\n",
      "User: Mkativerata, Out-degree: 191\n",
      "User: Hokeman, Out-degree: 168\n",
      "User: Tryptofish, Out-degree: 165\n",
      "User: HJ Mitchell, Out-degree: 164\n",
      "User: WereSpielChequers, Out-degree: 163\n",
      "User: Wizardman, Out-degree: 160\n",
      "User: Secret, Out-degree: 158\n",
      "User: Airplaneman, Out-degree: 158\n",
      "User: MC10, Out-degree: 151\n",
      "User: Newyorkbrad, Out-degree: 146\n",
      "User: Jusdafax, Out-degree: 142\n",
      "User: Ret.Prof, Out-degree: 140\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Assuming G is your directed graph\n",
    "\n",
    "# Get the in-degree and out-degree of all nodes\n",
    "in_degree_dict = dict(G.in_degree())\n",
    "out_degree_dict = dict(G.out_degree())\n",
    "\n",
    "# Combine in-degree and out-degree for each node\n",
    "degree_info = {\n",
    "    node: {\"in_degree\": in_degree_dict.get(node, 0), \"out_degree\": out_degree_dict.get(node, 0)}\n",
    "    for node in G.nodes()\n",
    "}\n",
    "\n",
    "# Sort nodes by in-degree and out-degree\n",
    "top_20_in_degree = sorted(degree_info.items(), key=lambda x: x[1][\"in_degree\"], reverse=True)[:20]\n",
    "top_20_out_degree = sorted(degree_info.items(), key=lambda x: x[1][\"out_degree\"], reverse=True)[:20]\n",
    "\n",
    "# Print the top 20 nodes with in-degree and out-degree\n",
    "print(\"Top 20 nodes by in-degree:\")\n",
    "for node, degrees in top_20_in_degree:\n",
    "    print(f\"User: {node}, In-degree: {degrees['in_degree']}\")\n",
    "\n",
    "print(\"\\nTop 20 nodes by out-degree:\")\n",
    "for node, degrees in top_20_out_degree:\n",
    "    print(f\"User: {node}, Out-degree: {degrees['out_degree']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0893484-fcd1-4c71-a5c3-c5af3b9e4957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges with VOT = 1: 0\n",
      "Edges with VOT = -1: 0\n",
      "Edges with VOT = 0: 32310\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "count_1 = 0\n",
    "count_neg1 = 0\n",
    "count_0 = 0\n",
    "\n",
    "# Loop through the edges of the graph\n",
    "for u, v, data in G.edges(data=True):\n",
    "    vot = data.get('weight', 0)  # Assuming 'weight' represents the VOT attribute\n",
    "    \n",
    "    # Count the VOT values\n",
    "    if vot == 1:\n",
    "        count_1 += 1\n",
    "    elif vot == -1:\n",
    "        count_neg1 += 1\n",
    "    elif vot == 0:\n",
    "        count_0 += 1\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Edges with VOT = 1: {count_1}\")\n",
    "print(f\"Edges with VOT = -1: {count_neg1}\")\n",
    "print(f\"Edges with VOT = 0: {count_0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb45d89a-d729-4c2a-b67a-16b533c7ba80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 nodes with the most 0 VOT as SRC:\n",
      "Boing! said Zebedee: 274\n",
      "Fetchcomms: 253\n",
      "Fastily: 251\n",
      "Ktr101: 249\n",
      "Axl: 211\n",
      "RP459: 198\n",
      "Kudpung: 197\n",
      "Minimac: 195\n",
      "Mkativerata: 191\n",
      "Hokeman: 168\n",
      "\n",
      "Top 10 nodes with the most 1 VOT as SRC:\n",
      "\n",
      "Top 10 nodes with the most -1 VOT as SRC:\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to count the occurrences of VOT values for each SRC\n",
    "src_0_count = {}\n",
    "src_1_count = {}\n",
    "src_neg1_count = {}\n",
    "\n",
    "# Iterate through the edges of the graph\n",
    "for u, v, data in G.edges(data=True):\n",
    "    vot = data.get('weight', 0)  # Assuming 'weight' represents the VOT attribute\n",
    "    \n",
    "    # Count the occurrences based on VOT values\n",
    "    if vot == 0:\n",
    "        if u in src_0_count:\n",
    "            src_0_count[u] += 1\n",
    "        else:\n",
    "            src_0_count[u] = 1\n",
    "    elif vot == 1:\n",
    "        if u in src_1_count:\n",
    "            src_1_count[u] += 1\n",
    "        else:\n",
    "            src_1_count[u] = 1\n",
    "    elif vot == -1:\n",
    "        if u in src_neg1_count:\n",
    "            src_neg1_count[u] += 1\n",
    "        else:\n",
    "            src_neg1_count[u] = 1\n",
    "\n",
    "# Sort the dictionaries by the count in descending order and get the top nodes\n",
    "top_0_src = sorted(src_0_count.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "top_1_src = sorted(src_1_count.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "top_neg1_src = sorted(src_neg1_count.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Print the top nodes with the most VOT as SRC for 0, 1, and -1\n",
    "print(\"Top 10 nodes with the most 0 VOT as SRC:\")\n",
    "for src, count in top_0_src:\n",
    "    print(f\"{src}: {count}\")\n",
    "\n",
    "print(\"\\nTop 10 nodes with the most 1 VOT as SRC:\")\n",
    "for src, count in top_1_src:\n",
    "    print(f\"{src}: {count}\")\n",
    "\n",
    "print(\"\\nTop 10 nodes with the most -1 VOT as SRC:\")\n",
    "for src, count in top_neg1_src:\n",
    "    print(f\"{src}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a2e2958-bfa3-4d43-ac80-8ea430445e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 voters by proportion of '0' votes:\n",
      "Node Boing! said Zebedee: 274 total votes, 100.00% were '0'\n",
      "Node Fetchcomms: 253 total votes, 100.00% were '0'\n",
      "Node Fastily: 251 total votes, 100.00% were '0'\n",
      "Node Ktr101: 249 total votes, 100.00% were '0'\n",
      "Node Axl: 211 total votes, 100.00% were '0'\n",
      "Node RP459: 198 total votes, 100.00% were '0'\n",
      "Node Kudpung: 197 total votes, 100.00% were '0'\n",
      "Node Minimac: 195 total votes, 100.00% were '0'\n",
      "Node Mkativerata: 191 total votes, 100.00% were '0'\n",
      "Node Hokeman: 168 total votes, 100.00% were '0'\n",
      "\n",
      "Top 10 voters by proportion of '1' votes:\n",
      "Node Boing! said Zebedee: 274 total votes, 0.00% were '1'\n",
      "Node Fetchcomms: 253 total votes, 0.00% were '1'\n",
      "Node Fastily: 251 total votes, 0.00% were '1'\n",
      "Node Ktr101: 249 total votes, 0.00% were '1'\n",
      "Node Axl: 211 total votes, 0.00% were '1'\n",
      "Node RP459: 198 total votes, 0.00% were '1'\n",
      "Node Kudpung: 197 total votes, 0.00% were '1'\n",
      "Node Minimac: 195 total votes, 0.00% were '1'\n",
      "Node Mkativerata: 191 total votes, 0.00% were '1'\n",
      "Node Hokeman: 168 total votes, 0.00% were '1'\n",
      "\n",
      "Top 10 voters by proportion of '-1' votes:\n",
      "Node Boing! said Zebedee: 274 total votes, 0.00% were '-1'\n",
      "Node Fetchcomms: 253 total votes, 0.00% were '-1'\n",
      "Node Fastily: 251 total votes, 0.00% were '-1'\n",
      "Node Ktr101: 249 total votes, 0.00% were '-1'\n",
      "Node Axl: 211 total votes, 0.00% were '-1'\n",
      "Node RP459: 198 total votes, 0.00% were '-1'\n",
      "Node Kudpung: 197 total votes, 0.00% were '-1'\n",
      "Node Minimac: 195 total votes, 0.00% were '-1'\n",
      "Node Mkativerata: 191 total votes, 0.00% were '-1'\n",
      "Node Hokeman: 168 total votes, 0.00% were '-1'\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to store the count of votes per node\n",
    "src_0_count = {}\n",
    "src_1_count = {}\n",
    "src_neg1_count = {}\n",
    "src_total_count = {}\n",
    "\n",
    "# Iterate through the edges of the graph\n",
    "for u, v, data in G.edges(data=True):\n",
    "    vot = data.get('weight', 0)  # Assuming 'weight' represents the VOT attribute\n",
    "    \n",
    "    # Track the total number of votes for each node (SRC)\n",
    "    if u in src_total_count:\n",
    "        src_total_count[u] += 1\n",
    "    else:\n",
    "        src_total_count[u] = 1\n",
    "    \n",
    "    # Count the occurrences based on VOT values\n",
    "    if vot == 0:\n",
    "        src_0_count[u] = src_0_count.get(u, 0) + 1\n",
    "    elif vot == 1:\n",
    "        src_1_count[u] = src_1_count.get(u, 0) + 1\n",
    "    elif vot == -1:\n",
    "        src_neg1_count[u] = src_neg1_count.get(u, 0) + 1\n",
    "\n",
    "# Sort the nodes by total votes and select the top 100\n",
    "top_100_voters = sorted(src_total_count.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Now calculate the proportion of each type of vote for the top 100 voters\n",
    "vote_proportions = []\n",
    "\n",
    "for node, total_votes in top_100_voters:\n",
    "    prop_0 = src_0_count.get(node, 0) / total_votes\n",
    "    prop_1 = src_1_count.get(node, 0) / total_votes\n",
    "    prop_neg1 = src_neg1_count.get(node, 0) / total_votes\n",
    "    \n",
    "    vote_proportions.append({\n",
    "        'node': node,\n",
    "        'total_votes': total_votes,\n",
    "        '0': prop_0,\n",
    "        '1': prop_1,\n",
    "        '-1': prop_neg1\n",
    "    })\n",
    "\n",
    "# Rank voters within the top 100 by their proportion of votes of each type\n",
    "ranked_0 = sorted(vote_proportions, key=lambda x: x['0'], reverse=True)[:10]\n",
    "ranked_1 = sorted(vote_proportions, key=lambda x: x['1'], reverse=True)[:10]\n",
    "ranked_neg1 = sorted(vote_proportions, key=lambda x: x['-1'], reverse=True)[:10]\n",
    "\n",
    "# Output the results\n",
    "print(\"Top 10 voters by proportion of '0' votes:\")\n",
    "for voter in ranked_0:\n",
    "    print(f\"Node {voter['node']}: {voter['total_votes']} total votes, {voter['0']*100:.2f}% were '0'\")\n",
    "\n",
    "print(\"\\nTop 10 voters by proportion of '1' votes:\")\n",
    "for voter in ranked_1:\n",
    "    print(f\"Node {voter['node']}: {voter['total_votes']} total votes, {voter['1']*100:.2f}% were '1'\")\n",
    "\n",
    "print(\"\\nTop 10 voters by proportion of '-1' votes:\")\n",
    "for voter in ranked_neg1:\n",
    "    print(f\"Node {voter['node']}: {voter['total_votes']} total votes, {voter['-1']*100:.2f}% were '-1'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c786c02-5e48-4569-b293-f9feec57bff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vote types for Neelix:\n",
      "VOT\n",
      " 1    69\n",
      "-1    14\n",
      " 0    12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where the target ('TGT') is \"Neelix\"\n",
    "votes_on_neelix = df_cleaned[df_cleaned['TGT'].str.contains(\"Neelix\", case=False, na=False)]\n",
    "\n",
    "# Count the types of votes based on the 'VOT' column\n",
    "vote_counts = votes_on_neelix['VOT'].value_counts()\n",
    "\n",
    "# Display the result\n",
    "print(\"Vote types for Neelix:\")\n",
    "print(vote_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b1b10a-5e00-4768-8011-a1811c2b879f",
   "metadata": {},
   "source": [
    "### Centrality Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e9a7751-a7d8-4f80-9bf5-dcb8ab399ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph exported to rfawiki_graph.gexf\n"
     ]
    }
   ],
   "source": [
    "G = create_signed_graph(df_cleaned)\n",
    "\n",
    "def prepare_graph_for_gephi(G):\n",
    "    \"\"\"Prepares the graph by ensuring all attributes are strings for Gephi compatibility.\"\"\"\n",
    "    for u, v, key, data in G.edges(data=True, keys=True):\n",
    "        for attr, value in data.items():\n",
    "            if not isinstance(value, str):\n",
    "                G[u][v][key][attr] = str(value)  # Convert non-strings to strings\n",
    "    return G\n",
    "\n",
    "# Prepare the graph\n",
    "G_prepared = prepare_graph_for_gephi(G)\n",
    "\n",
    "# Export to GEXF\n",
    "output_file = \"rfawiki_graph.gexf\"\n",
    "nx.write_gexf(G_prepared, output_file)\n",
    "print(f\"Graph exported to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ADC)",
   "language": "python",
   "name": "adc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
