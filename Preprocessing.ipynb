{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "325970e9-cb2e-4fb4-9ece-10af0733e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6acaea-c07e-4be2-8108-2ca3d132534b",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31b8fdcf-28d3-4f0b-a060-a3ab180bbde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Data/ground/wiki-RfA.txt'\n",
    "\n",
    "output_file = 'Data/wiki_RfA_2010_2013.csv'\n",
    "\n",
    "\n",
    "def process_file_to_dataframe(file_path):\n",
    "    # Read the text file as lines\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Split the content by empty lines\n",
    "    entries = content.strip().split('\\n\\n')\n",
    "\n",
    "    # List to store the entries in a structured format\n",
    "    data = []\n",
    "\n",
    "    # Process each entry\n",
    "    for entry in entries:\n",
    "        entry_dict = {}\n",
    "        for line in entry.split('\\n'):\n",
    "            if \":\" in line:\n",
    "                key, value = line.split(\":\", 1)\n",
    "                entry_dict[key.strip()] = value.strip()\n",
    "        data.append(entry_dict)\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Process and filter the data by year (2010 to 2013)\n",
    "def filter_data_by_year(df):\n",
    "    # Convert 'YEA' column to numeric, errors='coerce' will convert non-numeric to NaN\n",
    "    df['YEA'] = pd.to_numeric(df['YEA'], errors='coerce')\n",
    "\n",
    "    # Filter the DataFrame for years between 2010 and 2013\n",
    "    filtered_df = df[(df['YEA'] >= 2008) & (df['YEA'] <= 2013)]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Write the filtered data to a CSV file\n",
    "def write_csv_file(df, output_file):\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2eed568-e073-4d08-adfc-3dae175dc8a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Main processing pipeline\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m process_file_to_dataframe(file_path)  \u001b[38;5;66;03m# Process the file into a DataFrame\u001b[39;00m\n\u001b[1;32m      3\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m filter_data_by_year(df)      \u001b[38;5;66;03m# Filter data for 2010-2013\u001b[39;00m\n\u001b[1;32m      4\u001b[0m write_csv_file(filtered_df, output_file)   \u001b[38;5;66;03m# Write the filtered data to CSV\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 27\u001b[0m, in \u001b[0;36mprocess_file_to_dataframe\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend(entry_dict)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Convert the list of dictionaries to a DataFrame\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Main processing pipeline\n",
    "df = process_file_to_dataframe(file_path)  # Process the file into a DataFrame\n",
    "filtered_df = filter_data_by_year(df)      # Filter data for 2010-2013\n",
    "write_csv_file(filtered_df, output_file)   # Write the filtered data to CSV\n",
    "\n",
    "print(f\"CSV file with data from 2010 to 2013 has been written to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a455d-3dee-493b-9609-0ca6ae696eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8564e88f-45ad-4242-9a15-38e18a914f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: Index(['SRC', 'TGT', 'VOT', 'RES', 'YEA', 'DAT', 'TXT'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rfaSet = 'Data/wiki_RfA_2010_2013.csv'\n",
    "\n",
    "\n",
    "df = pd.read_csv(rfaSet)\n",
    "print(\"Columns in DataFrame:\", df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65146c0a-04b4-43e3-9750-3b0942128d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC</th>\n",
       "      <th>TGT</th>\n",
       "      <th>VOT</th>\n",
       "      <th>RES</th>\n",
       "      <th>YEA</th>\n",
       "      <th>DAT</th>\n",
       "      <th>TXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steel1943</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>23:13, 19 April 2013</td>\n",
       "      <td>'''Support''' as co-nom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cuchullain</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>01:04, 20 April 2013</td>\n",
       "      <td>'''Support''' as nominator.--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INeverCry</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>23:43, 19 April 2013</td>\n",
       "      <td>'''Support''' per noms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cncmaster</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>00:11, 20 April 2013</td>\n",
       "      <td>'''Support''' per noms. BDD is a strong contri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Miniapolis</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>00:56, 20 April 2013</td>\n",
       "      <td>'''Support''', with great pleasure. I work wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32567</th>\n",
       "      <td>Atama</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>18:17, 22 February 2010</td>\n",
       "      <td>'''Oppose''' - Per Polargeo, and per [http://e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32568</th>\n",
       "      <td>Bradjamesbrown</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>18:18, 22 February 2010</td>\n",
       "      <td>'''Oppose''' per SilkTork's diff above. Assert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32569</th>\n",
       "      <td>Ottawa4ever</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>18:11, 22 February 2010</td>\n",
       "      <td>'''Neutral''' Not to pile on, neutral. I canno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32570</th>\n",
       "      <td>Tryptofish</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>17:58, 22 February 2010</td>\n",
       "      <td>'''Neutral''' I've interacted with this editor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32571</th>\n",
       "      <td>The High Fin Sperm Whale</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>18:34, 22 February 2010</td>\n",
       "      <td>'''Neutral''' Although we do need more admins ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32572 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            SRC     TGT  VOT  RES   YEA  \\\n",
       "0                     Steel1943     BDD    1    1  2013   \n",
       "1                    Cuchullain     BDD    1    1  2013   \n",
       "2                     INeverCry     BDD    1    1  2013   \n",
       "3                     Cncmaster     BDD    1    1  2013   \n",
       "4                    Miniapolis     BDD    1    1  2013   \n",
       "...                         ...     ...  ...  ...   ...   \n",
       "32567                     Atama  ZooPro   -1   -1  2010   \n",
       "32568            Bradjamesbrown  ZooPro   -1   -1  2010   \n",
       "32569               Ottawa4ever  ZooPro    0   -1  2010   \n",
       "32570                Tryptofish  ZooPro    0   -1  2010   \n",
       "32571  The High Fin Sperm Whale  ZooPro    0   -1  2010   \n",
       "\n",
       "                           DAT  \\\n",
       "0         23:13, 19 April 2013   \n",
       "1         01:04, 20 April 2013   \n",
       "2         23:43, 19 April 2013   \n",
       "3         00:11, 20 April 2013   \n",
       "4         00:56, 20 April 2013   \n",
       "...                        ...   \n",
       "32567  18:17, 22 February 2010   \n",
       "32568  18:18, 22 February 2010   \n",
       "32569  18:11, 22 February 2010   \n",
       "32570  17:58, 22 February 2010   \n",
       "32571  18:34, 22 February 2010   \n",
       "\n",
       "                                                     TXT  \n",
       "0                               '''Support''' as co-nom.  \n",
       "1                          '''Support''' as nominator.--  \n",
       "2                                '''Support''' per noms.  \n",
       "3      '''Support''' per noms. BDD is a strong contri...  \n",
       "4      '''Support''', with great pleasure. I work wit...  \n",
       "...                                                  ...  \n",
       "32567  '''Oppose''' - Per Polargeo, and per [http://e...  \n",
       "32568  '''Oppose''' per SilkTork's diff above. Assert...  \n",
       "32569  '''Neutral''' Not to pile on, neutral. I canno...  \n",
       "32570  '''Neutral''' I've interacted with this editor...  \n",
       "32571  '''Neutral''' Although we do need more admins ...  \n",
       "\n",
       "[32572 rows x 7 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ddd669-66ec-401f-96d2-27e356004fe9",
   "metadata": {},
   "source": [
    "#### Treating time DAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9af3a72-d0a5-4f78-869f-6b1412beeadd",
   "metadata": {},
   "source": [
    "removing edges with not time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcb9f2c6-da8d-4477-9b45-17db45980d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SRC                TGT  VOT  RES   YEA DAT  \\\n",
      "707            NaN        Jason Quinn    0    1  2013 NaT   \n",
      "708            NaN        Jason Quinn    0    1  2013 NaT   \n",
      "793            NaN            Legoktm    1    1  2013 NaT   \n",
      "969    Majoreditor          Lord Roem    1    1  2013 NaT   \n",
      "1126           NaN      Mattythewhite   -1    1  2013 NaT   \n",
      "...            ...                ...  ...  ...   ...  ..   \n",
      "32310      Davidwr           Venomcuz   -1   -1  2010 NaT   \n",
      "32346       Begoon      White Shadows   -1   -1  2010 NaT   \n",
      "32350          NaN      White Shadows   -1   -1  2010 NaT   \n",
      "32394          NaN         WikiCopter   -1   -1  2010 NaT   \n",
      "32522          NaN  William S. Saturn   -1   -1  2010 NaT   \n",
      "\n",
      "                                                     TXT  \n",
      "707                                                  NaN  \n",
      "708                                                  NaN  \n",
      "793                                                  NaN  \n",
      "969    '''Support'''. The candidate is a good content...  \n",
      "1126                                                 NaN  \n",
      "...                                                  ...  \n",
      "32310                                       '''Oppose'''  \n",
      "32346  '''Oppose''' Sorry. I can't support with the m...  \n",
      "32350                                                NaN  \n",
      "32394                                                NaN  \n",
      "32522                                                NaN  \n",
      "\n",
      "[262 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'DAT' column to datetime, invalid parsing will result in NaT\n",
    "df['DAT'] = pd.to_datetime(df['DAT'], format='%H:%M, %d %B %Y', errors='coerce')\n",
    "\n",
    "# Filter rows where 'DAT' is NaT\n",
    "nat_rows = df[df['DAT'].isna()]\n",
    "\n",
    "# Display the rows with NaT in the 'DAT' column\n",
    "print(nat_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99daf37f-0175-4788-9dce-42fe88d5abdf",
   "metadata": {},
   "source": [
    "out of 32522 we found 262 edges with invalid/ NaN time - removing them for a better analysis and inegration of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127833c4-fe57-46a9-b1f0-0f31d828db26",
   "metadata": {},
   "source": [
    "#### removing those DAT timeless edges - RUN ONLY ONCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc61e184-baed-411d-935b-3a8f38069206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with NA in DAT: 262\n",
      "Number of rows with NA in DAT: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(rfaSet)\n",
    "\n",
    "# Convert 'DAT' to datetime, coercing errors to NaT (invalid datetimes)\n",
    "df['DAT'] = pd.to_datetime(df['DAT'], format='%H:%M, %d %B %Y', errors='coerce')\n",
    "\n",
    "na_count = df['DAT'].isna().sum()\n",
    "print(f\"Number of rows with NA in DAT: {na_count}\")\n",
    "\n",
    "# Remove rows where DAT is NaT (missing or invalid datetime)\n",
    "df_cleaned = df.dropna(subset=['DAT'])\n",
    "\n",
    "\n",
    "na_count = df_cleaned['DAT'].isna().sum()\n",
    "print(f\"Number of rows with NA in DAT: {na_count}\")\n",
    "\n",
    "# Print the cleaned dataframe\n",
    "write_csv_file(df_cleaned, output_file)  \n",
    "\n",
    "#preprocessing DONE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d52d53-c927-4ee0-8c4f-5b6c90daacc5",
   "metadata": {},
   "source": [
    "##### PRE PROCESSING DONE - JUST USE THE CLEANED CVS FILE FROM NOW ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee545945-d068-427e-8b66-459b54fc5838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC</th>\n",
       "      <th>TGT</th>\n",
       "      <th>VOT</th>\n",
       "      <th>RES</th>\n",
       "      <th>YEA</th>\n",
       "      <th>DAT</th>\n",
       "      <th>TXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steel1943</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-19 23:13:00</td>\n",
       "      <td>'''Support''' as co-nom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cuchullain</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-20 01:04:00</td>\n",
       "      <td>'''Support''' as nominator.--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INeverCry</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-19 23:43:00</td>\n",
       "      <td>'''Support''' per noms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cncmaster</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-20 00:11:00</td>\n",
       "      <td>'''Support''' per noms. BDD is a strong contri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Miniapolis</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-20 00:56:00</td>\n",
       "      <td>'''Support''', with great pleasure. I work wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32305</th>\n",
       "      <td>Atama</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:17:00</td>\n",
       "      <td>'''Oppose''' - Per Polargeo, and per [http://e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32306</th>\n",
       "      <td>Bradjamesbrown</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:18:00</td>\n",
       "      <td>'''Oppose''' per SilkTork's diff above. Assert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32307</th>\n",
       "      <td>Ottawa4ever</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:11:00</td>\n",
       "      <td>'''Neutral''' Not to pile on, neutral. I canno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32308</th>\n",
       "      <td>Tryptofish</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 17:58:00</td>\n",
       "      <td>'''Neutral''' I've interacted with this editor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32309</th>\n",
       "      <td>The High Fin Sperm Whale</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:34:00</td>\n",
       "      <td>'''Neutral''' Although we do need more admins ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32310 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            SRC     TGT  VOT  RES   YEA                  DAT  \\\n",
       "0                     Steel1943     BDD    1    1  2013  2013-04-19 23:13:00   \n",
       "1                    Cuchullain     BDD    1    1  2013  2013-04-20 01:04:00   \n",
       "2                     INeverCry     BDD    1    1  2013  2013-04-19 23:43:00   \n",
       "3                     Cncmaster     BDD    1    1  2013  2013-04-20 00:11:00   \n",
       "4                    Miniapolis     BDD    1    1  2013  2013-04-20 00:56:00   \n",
       "...                         ...     ...  ...  ...   ...                  ...   \n",
       "32305                     Atama  ZooPro   -1   -1  2010  2010-02-22 18:17:00   \n",
       "32306            Bradjamesbrown  ZooPro   -1   -1  2010  2010-02-22 18:18:00   \n",
       "32307               Ottawa4ever  ZooPro    0   -1  2010  2010-02-22 18:11:00   \n",
       "32308                Tryptofish  ZooPro    0   -1  2010  2010-02-22 17:58:00   \n",
       "32309  The High Fin Sperm Whale  ZooPro    0   -1  2010  2010-02-22 18:34:00   \n",
       "\n",
       "                                                     TXT  \n",
       "0                               '''Support''' as co-nom.  \n",
       "1                          '''Support''' as nominator.--  \n",
       "2                                '''Support''' per noms.  \n",
       "3      '''Support''' per noms. BDD is a strong contri...  \n",
       "4      '''Support''', with great pleasure. I work wit...  \n",
       "...                                                  ...  \n",
       "32305  '''Oppose''' - Per Polargeo, and per [http://e...  \n",
       "32306  '''Oppose''' per SilkTork's diff above. Assert...  \n",
       "32307  '''Neutral''' Not to pile on, neutral. I canno...  \n",
       "32308  '''Neutral''' I've interacted with this editor...  \n",
       "32309  '''Neutral''' Although we do need more admins ...  \n",
       "\n",
       "[32310 rows x 7 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Data/wiki_RfA_2010_2013.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0bce7e99-4739-4b4a-bae1-4f44f78416a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC</th>\n",
       "      <th>TGT</th>\n",
       "      <th>VOT</th>\n",
       "      <th>RES</th>\n",
       "      <th>YEA</th>\n",
       "      <th>DAT</th>\n",
       "      <th>TXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steel1943</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-19 23:13:00</td>\n",
       "      <td>'''''' as co-nom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cuchullain</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-20 01:04:00</td>\n",
       "      <td>'''''' as nominator.--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INeverCry</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-19 23:43:00</td>\n",
       "      <td>'''''' per noms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cncmaster</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-20 00:11:00</td>\n",
       "      <td>'''''' per noms. BDD is a strong contributor w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Miniapolis</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-20 00:56:00</td>\n",
       "      <td>'''''', with great pleasure. I work with BDD a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32305</th>\n",
       "      <td>Atama</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:17:00</td>\n",
       "      <td>'''''' - Per Polargeo, and per [http://en.wiki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32306</th>\n",
       "      <td>Bradjamesbrown</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:18:00</td>\n",
       "      <td>'''''' per SilkTork's diff above. Asserting [[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32307</th>\n",
       "      <td>Ottawa4ever</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:11:00</td>\n",
       "      <td>'''''' Not to pile on, neutral. I cannot suppo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32308</th>\n",
       "      <td>Tryptofish</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 17:58:00</td>\n",
       "      <td>'''''' I've interacted with this editor at var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32309</th>\n",
       "      <td>The High Fin Sperm Whale</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:34:00</td>\n",
       "      <td>'''''' Although we do need more admins in [[WP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32310 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            SRC     TGT  VOT  RES   YEA                  DAT  \\\n",
       "0                     Steel1943     BDD    1    1  2013  2013-04-19 23:13:00   \n",
       "1                    Cuchullain     BDD    1    1  2013  2013-04-20 01:04:00   \n",
       "2                     INeverCry     BDD    1    1  2013  2013-04-19 23:43:00   \n",
       "3                     Cncmaster     BDD    1    1  2013  2013-04-20 00:11:00   \n",
       "4                    Miniapolis     BDD    1    1  2013  2013-04-20 00:56:00   \n",
       "...                         ...     ...  ...  ...   ...                  ...   \n",
       "32305                     Atama  ZooPro   -1   -1  2010  2010-02-22 18:17:00   \n",
       "32306            Bradjamesbrown  ZooPro   -1   -1  2010  2010-02-22 18:18:00   \n",
       "32307               Ottawa4ever  ZooPro    0   -1  2010  2010-02-22 18:11:00   \n",
       "32308                Tryptofish  ZooPro    0   -1  2010  2010-02-22 17:58:00   \n",
       "32309  The High Fin Sperm Whale  ZooPro    0   -1  2010  2010-02-22 18:34:00   \n",
       "\n",
       "                                                     TXT  \n",
       "0                                      '''''' as co-nom.  \n",
       "1                                 '''''' as nominator.--  \n",
       "2                                       '''''' per noms.  \n",
       "3      '''''' per noms. BDD is a strong contributor w...  \n",
       "4      '''''', with great pleasure. I work with BDD a...  \n",
       "...                                                  ...  \n",
       "32305  '''''' - Per Polargeo, and per [http://en.wiki...  \n",
       "32306  '''''' per SilkTork's diff above. Asserting [[...  \n",
       "32307  '''''' Not to pile on, neutral. I cannot suppo...  \n",
       "32308  '''''' I've interacted with this editor at var...  \n",
       "32309  '''''' Although we do need more admins in [[WP...  \n",
       "\n",
       "[32310 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove 'Support', 'Oppose', and 'Neutral' from the 'TXT' column\n",
    "df['TXT'] = df['TXT'].str.replace('Support', '', regex=False)\n",
    "df['TXT'] = df['TXT'].str.replace('Oppose', '', regex=False)\n",
    "df['TXT'] = df['TXT'].str.replace('Neutral', '', regex=False)\n",
    "\n",
    "# Optionally, strip any extra spaces\n",
    "df['TXT'] = df['TXT'].str.strip()\n",
    "\n",
    "# Preview the updated DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd7f32d-dcdf-41e5-ba20-456e559dafd4",
   "metadata": {},
   "source": [
    "#### Remove 0 label edges, they cant be worked that well in terms of Social Connection theories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad386170-287c-4a02-acd1-550c3c5b5b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows: 30252\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC</th>\n",
       "      <th>TGT</th>\n",
       "      <th>VOT</th>\n",
       "      <th>RES</th>\n",
       "      <th>YEA</th>\n",
       "      <th>DAT</th>\n",
       "      <th>TXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steel1943</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-19 23:13:00</td>\n",
       "      <td>'''''' as co-nom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cuchullain</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-20 01:04:00</td>\n",
       "      <td>'''''' as nominator.--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INeverCry</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-19 23:43:00</td>\n",
       "      <td>'''''' per noms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cncmaster</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-20 00:11:00</td>\n",
       "      <td>'''''' per noms. BDD is a strong contributor w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Miniapolis</td>\n",
       "      <td>BDD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04-20 00:56:00</td>\n",
       "      <td>'''''', with great pleasure. I work with BDD a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30247</th>\n",
       "      <td>Smithers7</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 16:06:00</td>\n",
       "      <td>'''[[User:Smithers7/RfA|]]''' - ZooPro mention...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30248</th>\n",
       "      <td>SilkTork</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 17:18:00</td>\n",
       "      <td>'''''' because of the concerns already raised,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30249</th>\n",
       "      <td>GlassCobra</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:14:00</td>\n",
       "      <td>'''''' per Tanthalas and SilkTork.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30250</th>\n",
       "      <td>Atama</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:17:00</td>\n",
       "      <td>'''''' - Per Polargeo, and per [http://en.wiki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30251</th>\n",
       "      <td>Bradjamesbrown</td>\n",
       "      <td>ZooPro</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-02-22 18:18:00</td>\n",
       "      <td>'''''' per SilkTork's diff above. Asserting [[...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30252 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  SRC     TGT  VOT  RES   YEA                  DAT  \\\n",
       "0           Steel1943     BDD    1    1  2013  2013-04-19 23:13:00   \n",
       "1          Cuchullain     BDD    1    1  2013  2013-04-20 01:04:00   \n",
       "2           INeverCry     BDD    1    1  2013  2013-04-19 23:43:00   \n",
       "3           Cncmaster     BDD    1    1  2013  2013-04-20 00:11:00   \n",
       "4          Miniapolis     BDD    1    1  2013  2013-04-20 00:56:00   \n",
       "...               ...     ...  ...  ...   ...                  ...   \n",
       "30247       Smithers7  ZooPro   -1   -1  2010  2010-02-22 16:06:00   \n",
       "30248        SilkTork  ZooPro   -1   -1  2010  2010-02-22 17:18:00   \n",
       "30249      GlassCobra  ZooPro   -1   -1  2010  2010-02-22 18:14:00   \n",
       "30250           Atama  ZooPro   -1   -1  2010  2010-02-22 18:17:00   \n",
       "30251  Bradjamesbrown  ZooPro   -1   -1  2010  2010-02-22 18:18:00   \n",
       "\n",
       "                                                     TXT  \n",
       "0                                      '''''' as co-nom.  \n",
       "1                                 '''''' as nominator.--  \n",
       "2                                       '''''' per noms.  \n",
       "3      '''''' per noms. BDD is a strong contributor w...  \n",
       "4      '''''', with great pleasure. I work with BDD a...  \n",
       "...                                                  ...  \n",
       "30247  '''[[User:Smithers7/RfA|]]''' - ZooPro mention...  \n",
       "30248  '''''' because of the concerns already raised,...  \n",
       "30249                 '''''' per Tanthalas and SilkTork.  \n",
       "30250  '''''' - Per Polargeo, and per [http://en.wiki...  \n",
       "30251  '''''' per SilkTork's diff above. Asserting [[...  \n",
       "\n",
       "[30252 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows where VOT is 0\n",
    "df = df[df['VOT'] != 0]\n",
    "\n",
    "# Reset the index to keep it clean (optional)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Confirm the change\n",
    "print(f\"Remaining rows: {len(df)}\")\n",
    "\n",
    "write_csv_file(df, output_file) \n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7f039f1-787b-417a-94a0-d2ea27f578e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming df is the DataFrame that you've already filtered and processed\n",
    "# Create a signed graph\n",
    "def create_signed_graph(df):\n",
    "    \"\"\"\n",
    "    Create a MultiDiGraph from a DataFrame with edges labeled by interaction type.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing columns for edges and attributes.\n",
    "\n",
    "    Returns:\n",
    "        G (nx.MultiDiGraph): The created graph.\n",
    "    \"\"\"\n",
    "    G = nx.MultiDiGraph()  # Use MultiDiGraph to allow multiple edges between nodes\n",
    "\n",
    "    # Iterate through the rows of the DataFrame to add edges and nodes\n",
    "    for _, row in df.iterrows():\n",
    "        src = row['SRC']  # Source node\n",
    "        tgt = row['TGT']  # Target node\n",
    "        vot = row['VOT']  # Label: -1, 1, or 0\n",
    "        txt = row['TXT']  # Additional textual information\n",
    "        res = row['RES']  # Admin status: 1 for admin, 0 for nonAdmin\n",
    "        dat = row['DAT']  # Date or timestamp attribute\n",
    "\n",
    "        # Add nodes if they don't already exist\n",
    "        if src not in G:\n",
    "            G.add_node(src)\n",
    "        if tgt not in G:\n",
    "            G.add_node(tgt)\n",
    "\n",
    "        # Determine admin status for the edge\n",
    "        admin_status = \"admin\" if res == 1 else \"nonAdmin\"\n",
    "\n",
    "        # Add edge with attributes, storing `VOT` as a label, not a weight\n",
    "        edge_attrs = {\n",
    "            'label': vot,   # Interaction type (-1, 0, 1)\n",
    "            'txt': txt,     # Additional text data\n",
    "            'admin': admin_status,  # Whether the interaction involves an admin\n",
    "            'DAT': dat      # Timestamp or date\n",
    "        }\n",
    "        G.add_edge(src, tgt, **edge_attrs)  # Add the edge with all attributes\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Create the signed graph\n",
    "G = create_signed_graph(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "237ef056-e2bc-4ce0-a7de-0e765268a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_gexf_file = 'signed_graph.gexf'\n",
    "\n",
    "nx.write_gexf(G, output_gexf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "915c28d6-7732-42de-aea4-d8c3261d9122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User HJ Mitchell ran in 3 different years: 2011, 2010, 2009.\n",
      "User Ironholds ran in 4 different years: 2011, 2010, 2009, 2008.\n",
      "User Everyking ran in 5 different years: 2010, 2009, 2008, 2007, 2006.\n",
      "User SarekOfVulcan ran in 2 different years: 2011, 2008.\n",
      "User The Thing That Should Not Be ran in 1 year: 2010.\n",
      "User Connormah ran in 1 year: 2010.\n",
      "User SarahStierch ran in 1 year: 2012.\n",
      "User Lord Roem ran in 2 different years: 2013, 2012.\n",
      "User Drmies ran in 1 year: 2011.\n",
      "User Σ ran in 1 year: 2012.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dd/q59hq4f165zf1s43dyw9y7d80000gn/T/ipykernel_3425/2505793796.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_data['Year'] = user_data['DAT'].dt.year\n",
      "/var/folders/dd/q59hq4f165zf1s43dyw9y7d80000gn/T/ipykernel_3425/2505793796.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_data['Year'] = user_data['DAT'].dt.year\n",
      "/var/folders/dd/q59hq4f165zf1s43dyw9y7d80000gn/T/ipykernel_3425/2505793796.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_data['Year'] = user_data['DAT'].dt.year\n",
      "/var/folders/dd/q59hq4f165zf1s43dyw9y7d80000gn/T/ipykernel_3425/2505793796.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_data['Year'] = user_data['DAT'].dt.year\n",
      "/var/folders/dd/q59hq4f165zf1s43dyw9y7d80000gn/T/ipykernel_3425/2505793796.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_data['Year'] = user_data['DAT'].dt.year\n",
      "/var/folders/dd/q59hq4f165zf1s43dyw9y7d80000gn/T/ipykernel_3425/2505793796.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_data['Year'] = user_data['DAT'].dt.year\n",
      "/var/folders/dd/q59hq4f165zf1s43dyw9y7d80000gn/T/ipykernel_3425/2505793796.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_data['Year'] = user_data['DAT'].dt.year\n",
      "/var/folders/dd/q59hq4f165zf1s43dyw9y7d80000gn/T/ipykernel_3425/2505793796.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_data['Year'] = user_data['DAT'].dt.year\n",
      "/var/folders/dd/q59hq4f165zf1s43dyw9y7d80000gn/T/ipykernel_3425/2505793796.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_data['Year'] = user_data['DAT'].dt.year\n",
      "/var/folders/dd/q59hq4f165zf1s43dyw9y7d80000gn/T/ipykernel_3425/2505793796.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_data['Year'] = user_data['DAT'].dt.year\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Ensure NLTK stopwords and lemmatizer resources are downloaded if needed\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "#-------------------------------------------------------\n",
    "# Additional text cleaning configuration\n",
    "#-------------------------------------------------------\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Add domain/project-specific stopwords\n",
    "custom_stops = {\n",
    "    'per', 'wp', 'notnow', 'nom', 'user', 'admin', 'candidate', 'wikipedia',\n",
    "    'rfaa', 'rfa', 'en', 'http', 'org', 'com', 'www', 'index', 'content',\n",
    "    'page', 'talk', 'oldid', 'diff'\n",
    "}\n",
    "stop_words = stop_words.union(custom_stops)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans a given text string by removing wiki markup, URLs, HTML tags,\n",
    "    non-alphanumeric chars, normalizing unicode, tokenizing, removing stopwords,\n",
    "    lemmatizing, and converting to lowercase.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Normalize unicode\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    \n",
    "    # Remove wiki markup and links\n",
    "    text = re.sub(r\"'{2,}\", '', text)         # remove sequences of apostrophes\n",
    "    text = re.sub(r\"\\[\\[.*?\\]\\]\", ' ', text)  # remove double-bracket wiki links\n",
    "    text = re.sub(r\"\\[http.*?\\]\", ' ', text)  # remove http links in brackets\n",
    "    text = re.sub(r\"http\\S+\", ' ', text)       # remove raw URLs\n",
    "    text = re.sub(r\"\\{\\{.*?\\}\\}\", ' ', text)   # remove templates\n",
    "    text = re.sub(r\"<.*?>\", ' ', text)         # remove HTML tags\n",
    "    \n",
    "    # Remove non-alphanumeric (except space)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", ' ', text)\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords and short tokens\n",
    "    tokens = [t for t in tokens if t not in stop_words and len(t) > 1]\n",
    "\n",
    "    # Lemmatize tokens\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "#-------------------------------------------------------\n",
    "# Preprocessing Functions\n",
    "#-------------------------------------------------------\n",
    "\n",
    "def process_file_to_dataframe(file_path):\n",
    "    \"\"\"\n",
    "    Read the wiki-RfA raw text file and parse it into a structured DataFrame.\n",
    "    Each RfA entry is separated by an empty line, and lines have 'KEY: VALUE'.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Split by empty lines to separate entries\n",
    "    entries = content.strip().split('\\n\\n')\n",
    "\n",
    "    data = []\n",
    "    for entry in entries:\n",
    "        entry_dict = {}\n",
    "        for line in entry.split('\\n'):\n",
    "            if \":\" in line:\n",
    "                key, value = line.split(\":\", 1)\n",
    "                entry_dict[key.strip()] = value.strip()\n",
    "        data.append(entry_dict)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_data_by_year(df, start_year=2010, end_year=2013):\n",
    "    \"\"\"\n",
    "    Filter the DataFrame for entries between the specified years (inclusive).\n",
    "    Converts YEA to numeric and filters based on it.\n",
    "    \"\"\"\n",
    "    df['YEA'] = pd.to_numeric(df['YEA'], errors='coerce')\n",
    "    filtered_df = df[(df['YEA'] >= start_year) & (df['YEA'] <= end_year)]\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "def clean_datetime(df, datetime_col='DAT', datetime_format='%H:%M, %d %B %Y'):\n",
    "    \"\"\"\n",
    "    Convert 'DAT' column to a datetime. Remove rows with invalid datetime.\n",
    "    \"\"\"\n",
    "    df[datetime_col] = pd.to_datetime(df[datetime_col], format=datetime_format, errors='coerce')\n",
    "    na_count = df[datetime_col].isna().sum()\n",
    "    if na_count > 0:\n",
    "        logging.warning(f\"Found {na_count} rows with invalid datetime in '{datetime_col}'. Removing them.\")\n",
    "    df = df.dropna(subset=[datetime_col])\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_keywords_from_text(df, text_col='TXT', keywords=None):\n",
    "    \"\"\"\n",
    "    Remove specified keywords from the text column. For ex: 'Support', 'Oppose', 'Neutral'.\n",
    "    \"\"\"\n",
    "    if keywords is None:\n",
    "        keywords = ['Support', 'Oppose', 'Neutral']\n",
    "    for kw in keywords:\n",
    "        df[text_col] = df[text_col].str.replace(kw, '', regex=False)\n",
    "    df[text_col] = df[text_col].str.strip()\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_zero_votes(df, vote_col='VOT'):\n",
    "    \"\"\"\n",
    "    Remove rows where 'VOT' = 0.\n",
    "    \"\"\"\n",
    "    initial_count = len(df)\n",
    "    df = df[df[vote_col] != 0]\n",
    "    removed_count = initial_count - len(df)\n",
    "    if removed_count > 0:\n",
    "        logging.info(f\"Removed {removed_count} rows with zero votes (VOT=0).\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def write_csv_file(df, output_file):\n",
    "    \"\"\"\n",
    "    Write the DataFrame to a CSV file with UTF-8 encoding.\n",
    "    \"\"\"\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    logging.info(f\"CSV file successfully written to {output_file}\")\n",
    "\n",
    "\n",
    "#-------------------------------------------------------\n",
    "# Main Execution\n",
    "#-------------------------------------------------------\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file_path = 'Data/ground/wiki-RfA.txt'\n",
    "    output_file = 'Data/wiki_RfA_2005_2013.csv'\n",
    "    \n",
    "    # Step 1: Parse raw file\n",
    "    logging.info(\"Processing raw file into DataFrame...\")\n",
    "    df = process_file_to_dataframe(file_path)\n",
    "    \n",
    "    # Step 2: Filter by year\n",
    "    logging.info(\"Filtering data by year (2008-2013)...\")\n",
    "    df = filter_data_by_year(df, 2005, 2013)\n",
    "    \n",
    "    # Step 3: Clean DAT column\n",
    "    logging.info(\"Cleaning DAT column...\")\n",
    "    df = clean_datetime(df, datetime_col='DAT', datetime_format='%H:%M, %d %B %Y')\n",
    "    \n",
    "    # Step 4: Remove 'Support', 'Oppose', 'Neutral' from TXT\n",
    "    logging.info(\"Removing specific keywords from TXT...\")\n",
    "    df = remove_keywords_from_text(df, text_col='TXT', keywords=['Support', 'Oppose', 'Neutral'])\n",
    "    \n",
    "    # Step 5: Remove zero-vote rows\n",
    "    logging.info(\"Removing zero-vote rows...\")\n",
    "    df = remove_zero_votes(df, vote_col='VOT')\n",
    "    \n",
    "    # Step 6: Apply the advanced text cleaning to a new column 'cleaned_TXT'\n",
    "    logging.info(\"Applying advanced text cleaning to 'TXT' column...\")\n",
    "    df['cleaned_TXT'] = df['TXT'].apply(clean_text)\n",
    "    \n",
    "    # Step 7: Write final cleaned DataFrame to CSV\n",
    "    write_csv_file(df, output_file)\n",
    "    \n",
    "    # Optionally show a sample\n",
    "    logging.info(\"Preprocessing complete. Here is a sample of the cleaned DataFrame:\")\n",
    "    logging.info(df[['TXT', 'cleaned_TXT']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a440545e-53a4-443a-ad48-c8b88759e6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ADC)",
   "language": "python",
   "name": "adc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
